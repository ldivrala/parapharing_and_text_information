{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parapharsing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNlbLm6uuNGSYnmwJY3GdUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldivrala/parapharing_and_text_information/blob/main/parapharsing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NE0zWa-7PAU",
        "outputId": "908f1708-5fc0-4b7c-a589-cbfda0e63660"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lredHQit7BS3"
      },
      "source": [
        "# from transformers import GPT2Tokenizer, TFGPT2Model\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRdDuwXQ657l",
        "outputId": "ad1a9307-3e56-4d70-a478-b1b9f2aecbec"
      },
      "source": [
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "AB2WNicnFjb3",
        "outputId": "69363356-8c28-4eac-d289-48a45a9a404c"
      },
      "source": [
        "train_data = pd.read_csv(\"/content/msr_paraphrase_train.txt\", \n",
        "                         delimiter=\"\\t\", \n",
        "                         error_bad_lines=False).rename(\n",
        "                             columns = {\"#1 String\": \"text\", \"#2 String\": \"para\"}\n",
        "                             )\n",
        "                         \n",
        "train_data.dropna(inplace = True)  \n",
        "train_data = train_data[train_data.Quality == 1]\n",
        "\n",
        "train_data2 = pd.read_table(\"train.tsv\")\n",
        "train_data2.dropna(inplace = True) \n",
        "train_data2.drop(columns = \"id\", inplace = True)\n",
        "train_data2 = train_data2[train_data2.label == 1]\n",
        "\n",
        "train_data2.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "b'Skipping line 102: expected 5 fields, saw 6\\nSkipping line 656: expected 5 fields, saw 6\\nSkipping line 867: expected 5 fields, saw 6\\nSkipping line 880: expected 5 fields, saw 6\\nSkipping line 980: expected 5 fields, saw 6\\nSkipping line 1439: expected 5 fields, saw 6\\nSkipping line 1473: expected 5 fields, saw 6\\nSkipping line 1822: expected 5 fields, saw 6\\nSkipping line 1952: expected 5 fields, saw 6\\nSkipping line 2009: expected 5 fields, saw 6\\nSkipping line 2230: expected 5 fields, saw 6\\nSkipping line 2506: expected 5 fields, saw 6\\nSkipping line 2523: expected 5 fields, saw 6\\nSkipping line 2809: expected 5 fields, saw 6\\nSkipping line 2887: expected 5 fields, saw 6\\nSkipping line 2920: expected 5 fields, saw 6\\nSkipping line 2944: expected 5 fields, saw 6\\nSkipping line 3241: expected 5 fields, saw 6\\nSkipping line 3358: expected 5 fields, saw 6\\nSkipping line 3459: expected 5 fields, saw 6\\nSkipping line 3491: expected 5 fields, saw 6\\nSkipping line 3643: expected 5 fields, saw 6\\nSkipping line 3696: expected 5 fields, saw 6\\nSkipping line 3955: expected 5 fields, saw 6\\n'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The NBA season of 1975 -- 76 was the 30th seas...</td>\n",
              "      <td>The 1975 -- 76 season of the National Basketba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When comparable rates of flow can be maintaine...</td>\n",
              "      <td>The results are high when comparable flow rate...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It is the seat of Zerendi District in Akmola R...</td>\n",
              "      <td>It is the seat of the district of Zerendi in A...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>William Henry Henry Harman was born on 17 Febr...</td>\n",
              "      <td>William Henry Harman was born in Waynesboro , ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>With a discrete amount of probabilities Formul...</td>\n",
              "      <td>Given a discrete set of probabilities formula ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentence1  ... label\n",
              "1  The NBA season of 1975 -- 76 was the 30th seas...  ...     1\n",
              "3  When comparable rates of flow can be maintaine...  ...     1\n",
              "4  It is the seat of Zerendi District in Akmola R...  ...     1\n",
              "5  William Henry Henry Harman was born on 17 Febr...  ...     1\n",
              "7  With a discrete amount of probabilities Formul...  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSWcRvymDOxO",
        "outputId": "fe7017b7-ff71-4d8f-8f71-ef460d043433"
      },
      "source": [
        "text_para1 = \"<S> \" + train_data[\"text\"] + \" </S>\" + \" <<<< \" + \"<P> \" + train_data[\"para\"] + \" </P>\"\n",
        "text_para2 = \"<S> \" + train_data[\"para\"] + \" </S>\" + \" <<<< \" + \"<P> \" + train_data[\"text\"] + \" </P>\"\n",
        "text_para3 = \"<S> \" + train_data2[\"sentence1\"] + \" </S>\" + \" <<<< \" + \"<P> \" + train_data2[\"sentence2\"] + \" </P>\"\n",
        "text_para4 = \"<S> \" + train_data2[\"sentence2\"] + \" </S>\" + \" <<<< \" + \"<P> \" + train_data2[\"sentence1\"] + \" </P>\"\n",
        "\n",
        "text_para1.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    <S> Amrozi accused his brother, whom he called...\n",
              "2    <S> They had published an advertisement on the...\n",
              "4    <S> The stock rose $2.11, or about 11 percent,...\n",
              "5    <S> Revenue in the first quarter of the year d...\n",
              "7    <S> The DVD-CCA then appealed to the state Sup...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C3K3YklGqrq",
        "outputId": "ba020eec-afe0-4ae9-8fab-e2a35d8b6bc9"
      },
      "source": [
        "text_para = text_para1.append([text_para2, text_para3, text_para4], ignore_index=True)\n",
        "\n",
        "text_para.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48945    <S> The Romance language currently spoken in G...\n",
              "48946    <S> It is necessary to note that k is a vector...\n",
              "48947    <S> Tim Tim Henman won 6 -- 2 , 7 -- 6 against...\n",
              "48948    <S> He was considered an active member of the ...\n",
              "48949    <S> She was at Cork on 24 June , and arrived i...\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlh9Mdrn8seA",
        "outputId": "3de9a705-8000-445d-813b-0a5ebad7e7de"
      },
      "source": [
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "wI8Qe87G70M4",
        "outputId": "c2495da6-844e-4a3e-c07f-a6cf9b2ffe5f"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "text_para = shuffle(text_para)\n",
        "\n",
        "text_para.iloc[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<S> In 1989 , he travelled to Mozambique , Johannesburg , and Angola , South Africa on a peace-seeking mission . </S> <<<< <P> In 1989 he travelled to South Africa , Johannesburg and Angola , Mozambique on a peace-seeking mission . </P>'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dzQ18pK-C9N"
      },
      "source": [
        "batch_size = 8\n",
        "\n",
        "def format_dataset():\n",
        "    for i in range(len(text_para)):\n",
        "      example = text_para.iloc[i]\n",
        "\n",
        "      tokens = tokenizer(example, \n",
        "                         return_tensors=\"tf\")\n",
        "      \n",
        "      yield ({\n",
        "          \"input_ids\": tokens[\"input_ids\"][0, :-1]\n",
        "      }, {\n",
        "          \"labels\": tokens[\"input_ids\"][0, 1:]\n",
        "      })\n",
        "\n",
        "def make_dataset(dataset):\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(format_dataset, \n",
        "                                             output_signature= ({\n",
        "                                                 \"input_ids\": tf.TensorSpec(shape=(None), dtype=tf.int32, name=\"input_ids\"),\n",
        "                                             },{\n",
        "                                                 \"labels\": tf.TensorSpec(shape=(None), dtype=tf.int32, name=\"labels\")\n",
        "                                             }))\n",
        "    dataset = dataset.cache()\n",
        "    \n",
        "    return dataset.padded_batch(batch_size, padded_shapes= ({\"input_ids\":[None]}, {\"labels\":[None]}))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJZICnmu_ujQ"
      },
      "source": [
        "train_ds = make_dataset(train_data)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NL0WIaDSAmlQ",
        "outputId": "049e26c7-51c4-438a-831a-d07ec6eb632f"
      },
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"input_ids\"].shape}')\n",
        "    # print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets['labels'].shape}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (8, 87)\n",
            "targets.shape: (8, 87)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sabbPbV8DEpd"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PrbJuwSDMpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ed480c-a098-46fd-a7f3-97e04fb73435"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_check = \"<S>\" + train_data[\"text\"].iloc[0] + \"</S>\" + \"<<<<\" \n",
        "input_ids = tokenizer.encode(input_check, return_tensors='tf')\n",
        "\n",
        "# generate text until the output length (which includes the context length) reaches 50\n",
        "greedy_output = model.generate(input_ids, max_length=100)\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "<S>Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.</S><<<<S>Amrozi said he had been told by the witness that he had been told by the witness that he had been told by the witness that he had been told by the witness that he had been told by the witness that he had been told by the witness that he had been told by the witness that he had been told by the witness that he had\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJziqA8r4OEo"
      },
      "source": [
        "input = tf.keras.Input(shape= (None, ), name=\"input_ids\", dtype = tf.int32)\n",
        "model_output = model(input).logits\n",
        "model_output = tf.keras.layers.Activation(\"softmax\", name=\"labels\")(model_output)\n",
        "model2 = tf.keras.Model(input, model_output)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qwG-4yW5DX6",
        "outputId": "f06e0388-498f-497a-89e0-5e72b6b06f47"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_ids (InputLayer)       [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "tfgp_t2lm_head_model (TFGPT2 TFCausalLMOutputWithPast( 124439808 \n",
            "_________________________________________________________________\n",
            "labels (Activation)          (None, None, 50257)       0         \n",
            "=================================================================\n",
            "Total params: 124,439,808\n",
            "Trainable params: 124,439,808\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1Gvtb61w6x5"
      },
      "source": [
        "model2.compile(\"adam\", tf.keras.losses.SparseCategoricalCrossentropy(), metrics = [\"acc\"])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqs74TxNvili",
        "outputId": "4bc368e5-3779-42d7-9a5d-bcb9660388a2"
      },
      "source": [
        "model2.fit(train_ds)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6119/6119 [==============================] - 1263s 204ms/step - loss: 1.4022 - acc: 0.7546\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabb7e75c10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ93j5id8YO7",
        "outputId": "988767d3-fdfe-4413-8927-7fb10f8b5d47"
      },
      "source": [
        "model2.fit(train_ds, epochs = 20)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "6119/6119 [==============================] - 1170s 191ms/step - loss: 0.8107 - acc: 0.8300\n",
            "Epoch 2/20\n",
            "6119/6119 [==============================] - 1170s 191ms/step - loss: 0.5711 - acc: 0.8718\n",
            "Epoch 3/20\n",
            "6119/6119 [==============================] - 1169s 191ms/step - loss: 0.4578 - acc: 0.8954\n",
            "Epoch 4/20\n",
            "6119/6119 [==============================] - 1171s 191ms/step - loss: 0.3957 - acc: 0.9093\n",
            "Epoch 5/20\n",
            "6119/6119 [==============================] - 1172s 191ms/step - loss: 0.3561 - acc: 0.9183\n",
            "Epoch 6/20\n",
            "6119/6119 [==============================] - 1174s 192ms/step - loss: 0.3276 - acc: 0.9248\n",
            "Epoch 7/20\n",
            "6119/6119 [==============================] - 1174s 192ms/step - loss: 0.3057 - acc: 0.9297\n",
            "Epoch 8/20\n",
            "6119/6119 [==============================] - 1173s 192ms/step - loss: 0.2884 - acc: 0.9335\n",
            "Epoch 9/20\n",
            "6119/6119 [==============================] - 1173s 192ms/step - loss: 0.2742 - acc: 0.9367\n",
            "Epoch 10/20\n",
            "6119/6119 [==============================] - 1174s 192ms/step - loss: 0.2618 - acc: 0.9395\n",
            "Epoch 11/20\n",
            "6119/6119 [==============================] - 1174s 192ms/step - loss: 0.2514 - acc: 0.9417\n",
            "Epoch 12/20\n",
            "6119/6119 [==============================] - 1174s 192ms/step - loss: 0.2421 - acc: 0.9437\n",
            "Epoch 13/20\n",
            "6119/6119 [==============================] - 1174s 192ms/step - loss: 0.2336 - acc: 0.9455\n",
            "Epoch 14/20\n",
            "6119/6119 [==============================] - 1174s 192ms/step - loss: 0.2257 - acc: 0.9472\n",
            "Epoch 15/20\n",
            "6119/6119 [==============================] - 1174s 192ms/step - loss: 0.2188 - acc: 0.9488\n",
            "Epoch 16/20\n",
            "6119/6119 [==============================] - 1174s 192ms/step - loss: 0.2122 - acc: 0.9503\n",
            "Epoch 17/20\n",
            "6119/6119 [==============================] - 1171s 191ms/step - loss: 0.2061 - acc: 0.9517\n",
            "Epoch 18/20\n",
            "6119/6119 [==============================] - 1169s 191ms/step - loss: 0.2009 - acc: 0.9528\n",
            "Epoch 19/20\n",
            "6119/6119 [==============================] - 1169s 191ms/step - loss: 0.1953 - acc: 0.9541\n",
            "Epoch 20/20\n",
            "6119/6119 [==============================] - 1170s 191ms/step - loss: 0.1905 - acc: 0.9553\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa9ee126750>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FHvfoHNAd-Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HodlLSDRv9B3",
        "outputId": "3d684c70-9865-4c40-c163-7bd8b37c7b2e"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_check = \"<S>\" + train_data[\"text\"].iloc[0] + \"</S>\" + \"<<<<\" \n",
        "input_ids = tokenizer.encode(input_check, return_tensors='tf')\n",
        "\n",
        "# generate text until the output length (which includes the context length) reaches 50\n",
        "greedy_output = model.generate(input_ids, max_length=100)\n",
        "\n",
        "print(\"Output:\\n\" + 50 * '-')\n",
        "output_para = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
        "output_para = output_para.split(\"<P>\")[1].split(\"</P>\")[0]\n",
        "\n",
        "print(input_check)\n",
        "print(output_para)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "--------------------------------------------------\n",
            "<S>Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.</S><<<<\n",
            " Referring to him as only \"the witness\", Amrozi accused his brother of deliberately distorting his evidence. </P> Referring to him as \"the witness\", Arraja said. </P> Referring to him. </P> The Associated Press afterward, a spokeswoman,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJD7BISMFs_2"
      },
      "source": [
        "# import numpy as np"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYYbXVQ6AaVy",
        "outputId": "f0e356e3-f5db-4eef-c06b-00e167fa87f4"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_check = \"<S>\" + \"how are you?\" + \"</S>\" + \"<<<<\" \n",
        "input_ids = tokenizer.encode(input_check, return_tensors='tf')\n",
        "\n",
        "# generate text until the output length (which includes the context length) reaches 50\n",
        "greedy_output = model.generate(input_ids, max_length=100, num_return_sequences = 20, do_sample=True)\n",
        "\n",
        "print(\"Output:\\n\" + 50 * '-')\n",
        "output_para = []\n",
        "\n",
        "for i in range(20):\n",
        "  para = tokenizer.decode(greedy_output[i], skip_special_tokens=True)\n",
        "  output_para.append(para.split(\"<P>\")[1].split(\"</P>\")[0])\n",
        "\n",
        "print(input_check)\n",
        "print(output_para[0])\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "--------------------------------------------------\n",
            "<S>how are you?</S><<<<\n",
            " In Perú fall there are issues such as ESPN,: For the first amber tournament there are those supporting the bottom-of-the-de-the-de-the-de-the-deighth. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8hGoN7YDUO_",
        "outputId": "f18c3173-fa08-4ad1-d9eb-7784d7d29d68"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n",
            "INFO:absl:Downloaded https://tfhub.dev/google/universal-sentence-encoder/4, Total size: 987.47MB\n",
            "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/google/universal-sentence-encoder/4'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwaONwMwGjif"
      },
      "source": [
        "sentence = \"Machine learning is an application of artificial intelligence (AI)\\\n",
        " that provides systems the ability to automatically learn and improve from experience\\\n",
        "  without being explicitly programmed. Machine learning focuses on the development of \\\n",
        "  computer programs that can access data and use it to learn for themselves.\\\n",
        "The process of learning begins with observations or data, such as examples, direct \\\n",
        "experience, or instruction, in order to look for patterns in data and make better \\\n",
        "decisions in the future based on the examples that we provide. The primary aim is \\\n",
        "to allow the computers learn automatically without human intervention or assistance \\\n",
        "and adjust actions accordingly.\"\n",
        "\n",
        "sentence_part = sentence.split(\".\")\n",
        "sentence_output = embed(tf.constant([sentence]))[0]\n",
        "sentence_part_output = embed(tf.constant(sentence_part))\n",
        "\n",
        "def cosine_similarity(vector,matrix):\n",
        "   return ( np.sum(vector*matrix,axis=1) / ( np.sqrt(np.sum(matrix**2,axis=1)) * np.sqrt(np.sum(vector**2)) ) )[::-1]"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suq-AurKHGMh",
        "outputId": "3eca37d1-0d25-408c-93d5-0fbc0e1211aa"
      },
      "source": [
        "(sentence_output.numpy() @ sentence_part_output.numpy().T).argsort()[::-1]"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 270
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JZOAvp7LPL09",
        "outputId": "e24b2fca-6720-453b-ccff-e35fba6c5693"
      },
      "source": [
        "sentence_part[0]"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience  without being explicitly programmed'"
            ]
          },
          "metadata": {},
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS18faimSyYh"
      },
      "source": [
        "import regex as re\n",
        "\n",
        "sentence_words = re.findall(\"[\\w]+\" ,sentence)\n",
        "sentence_words = sentence_words + re.findall(\"[\\w]+ [\\w]+\", sentence)\n",
        "\n",
        "sentence_words_output = embed(sentence_words)"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nAfJv0VS9-p",
        "outputId": "044e9292-b0ec-4dc4-fffd-2f2a7aad424f"
      },
      "source": [
        "sentence_words_similirity = (sentence_output.numpy() @ sentence_words_output.numpy().T).argsort()[::-1]\n",
        "sentence_words_similirity"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([114, 102, 105,   8, 124, 109, 145,  26,  48,   1, 117,  24, 137,\n",
              "       113,  90, 133, 144, 122, 129,  53,  68,  37, 126, 119, 135,   7,\n",
              "        32,  60, 107, 142,  75,  42,  16,  91, 146,  15,  92,  51,  85,\n",
              "        18,  33,  25,   0, 149, 100, 147,  44,  11, 106, 104,  10, 125,\n",
              "        66,  94, 139,  72, 115, 132, 116,  27,  30, 118,  79,  56, 110,\n",
              "        58,  20,  76,  13,  93,  21, 128, 108,  95, 140, 111, 148, 136,\n",
              "        49,  50,   4, 138,  23,  46, 121,   6,  82, 112, 130, 127,  36,\n",
              "        35, 120,  39,  99,   3,  71,  19, 123, 141,  52,  96,  59,  55,\n",
              "       134,  77,  28,  88,  61,  67,  73, 143,  87,  63,  41,  14,  97,\n",
              "        31,   5,  47,  78,  89,  12,  29,  45,  83,  74, 103,  54, 101,\n",
              "        40,  17,  98,  69,  38,  57,  62,  84,  80,  34,   9, 131,  81,\n",
              "        65,  43,   2,  86,  22,  70,  64])"
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oys9CE3aS_rs",
        "outputId": "20e27bb6-6068-402a-8cfa-f00407a8c347"
      },
      "source": [
        "np.array(sentence_words)[sentence_words_similirity]"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Machine learning', 'Machine learning', 'artificial intelligence',\n",
              "       'AI', 'of learning', 'automatically learn', 'learn automatically',\n",
              "       'learning', 'learning', 'learning', 'computer programs',\n",
              "       'programmed', 'future based', 'explicitly programmed', 'computers',\n",
              "       'in data', 'the computers', 'learn for', 'or instruction', 'data',\n",
              "       'data', 'data', 'observations or', 'access data',\n",
              "       'better decisions', 'intelligence', 'computer', 'instruction',\n",
              "       'systems the', 'aim is', 'future', 'learn', 'learn', 'learn',\n",
              "       'without human', 'automatically', 'automatically', 'observations',\n",
              "       'aim', 'improve', 'programs', 'Machine', 'Machine',\n",
              "       'adjust actions', 'actions', 'intervention or', 'themselves',\n",
              "       'systems', 'that provides', 'application of', 'provides',\n",
              "       'begins with', 'patterns', 'human', 'examples that', 'decisions',\n",
              "       'focuses on', 'for patterns', 'the development', 'focuses',\n",
              "       'development', 'that can', 'examples', 'examples', 'and improve',\n",
              "       'experience', 'experience', 'based', 'ability', 'without',\n",
              "       'without', 'direct experience', 'ability to', 'intervention',\n",
              "       'we provide', 'from experience', 'assistance and', 'in the',\n",
              "       'begins', 'with', 'application', 'on the', 'explicitly', 'process',\n",
              "       'it to', 'artificial', 'provide', 'without being', 'in order',\n",
              "       'such as', 'access', 'can', 'and use', 'use', 'adjust', 'an',\n",
              "       'better', 'from', 'The process', 'The primary', 'or', 'or', 'or',\n",
              "       'as', 'and make', 'on', 'on', 'allow', 'in', 'in', 'in',\n",
              "       'to allow', 'to', 'to', 'to', 'to', 'assistance', 'of', 'of', 'of',\n",
              "       'the', 'the', 'the', 'the', 'The', 'The', 'the', 'is an', 'such',\n",
              "       'accordingly', 'it', 'and', 'and', 'and', 'and', 'direct', 'order',\n",
              "       'primary', 'that', 'that', 'that', 'to look', 'we', 'for', 'for',\n",
              "       'is', 'is', 'being', 'make', 'look'], dtype='<U23')"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAC1PUi7UCj1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}